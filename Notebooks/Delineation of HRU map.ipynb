{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b6f1ab8",
   "metadata": {},
   "source": [
    "## This script delineates the HRU map of a watershed using the Physitel inputs/outputs. Note that the subbasin map created using previous script will be used for identificaction of subbasin ID of the HRUs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd78af",
   "metadata": {},
   "source": [
    "### Section 0: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9afca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin\n",
    "from rasterstats import zonal_stats\n",
    "import rasterio\n",
    "from rasterio.features import shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503a183",
   "metadata": {},
   "source": [
    "### Section 1: Read inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf845093",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathtoDirectory = r\"C:\\Users\\mohbiz1\\Desktop\\Dossier_travail\\Hydrotel\\DEH\\MG24HA\\SLSO_MG24HA_2020\\physitel\"\n",
    "workspace = os.path.join(pathtoDirectory+ \"\\HRU\")\n",
    "\n",
    "#Read the subbasin, land use, and soil maps\n",
    "\n",
    "subwshd_pth = os.path.join(workspace,\"subbasin_final\"+\".\"+\"shp\") #subwatershed map created by Hydrotel_Raven_V2 script\n",
    "lu_raster = os.path.join(workspace,\"occupation_sol\"+\".\"+\"tif\") #Lu map in raster\n",
    "soil_raster = os.path.join(workspace,\"type_sol\"+\".\"+\"tif\") #soil type map in raster\n",
    "lake = os.path.join(workspace,\"lacs\"+\".\"+\"shp\") #lake map\n",
    "altitude = os.path.join(workspace,\"altitude\"+ \".\" + \"tif\") # The altitude raster map\n",
    "aspect = os.path.join(workspace,\"aspect\"+ \".\" + \"tif\") # The aspect raster map\n",
    "slope = os.path.join(workspace,\"slope\"+ \".\" + \"tif\") # The slope raster map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041c449",
   "metadata": {},
   "source": [
    "### Section 2: Polygonizing the raster maps (land use, soil) for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# land use map\n",
    "\n",
    "with rasterio.Env():\n",
    "    with rasterio.open(lu_raster) as src:\n",
    "        lu = src.read(1) # first band\n",
    "        mask = src.dataset_mask()\n",
    "        ras_crs = src.crs\n",
    "        results = (\n",
    "        {'properties': {'LU_ID': v}, 'geometry': s}\n",
    "        for i, (s, v) \n",
    "        in enumerate(\n",
    "            shapes(lu, mask=mask, transform=src.transform)))\n",
    "\n",
    "geoms = list(results)\n",
    "lu_poly  = gpd.GeoDataFrame.from_features(geoms,crs=ras_crs)\n",
    "\n",
    "os.chdir(workspace)\n",
    "lu_poly.to_file('lu_test.shp')\n",
    "\n",
    "# soil\n",
    "\n",
    "with rasterio.Env():\n",
    "    with rasterio.open(soil_raster) as src:\n",
    "        soil = src.read(1) # first band\n",
    "        mask = src.dataset_mask()\n",
    "        ras_crs = src.crs\n",
    "        results = (\n",
    "        {'properties': {'soil_ID': v}, 'geometry': s}\n",
    "        for i, (s, v) \n",
    "        in enumerate(\n",
    "            shapes(soil, mask=mask, transform=src.transform)))\n",
    "\n",
    "geoms = list(results)\n",
    "soil_poly  = gpd.GeoDataFrame.from_features(geoms,crs=ras_crs)\n",
    "\n",
    "os.chdir(workspace)\n",
    "soil_poly.to_file('soil_type.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5927450",
   "metadata": {},
   "source": [
    "### Section 3: overlaying the soil and land use map to create the HRU map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1562ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hru1 = gpd.overlay(lu_poly, soil_poly, how='intersection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f193c",
   "metadata": {},
   "source": [
    "### Section 4: Finding the major land use and soil class in lake polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd4a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_poly = gpd.read_file(lake)\n",
    "# Union lake polygon with HRU map (a lake is a unique HRU)\n",
    "\n",
    "hru2 = gpd.overlay(lake_poly, hru1, how='intersection')\n",
    "hru3 = hru2.dissolve(by='ident',aggfunc = 'first') #aggregate all the polygons that are lake in the hru\n",
    "hru4 = gpd.overlay(hru1, hru3, how='symmetric_difference')\n",
    "hru5 = gpd.overlay(hru4, hru3, how='union')\n",
    "\n",
    "hru6 = sjoin(lake_poly,hru5,how = 'right',op='within')\n",
    "# os.chdir(workspace)\n",
    "# hru6.to_file('hru6.shp')\n",
    "\n",
    "hru6['LU'] = 0\n",
    "hru6['SOIL'] = 0\n",
    "for index, row in hru6.iterrows():\n",
    "    if hru6.loc[index,'ident'] < 0 and hru6.loc[index,'ident'] != 'nan':\n",
    "        hru6.loc[index,'LU'] =2\n",
    "        hru6.loc[index,'SOIL'] = hru6.loc[index,'soil_ID']\n",
    "    else:\n",
    "        hru6.loc[index,'LU'] = hru6.loc[index,'LU_ID_1']\n",
    "        hru6.loc[index,'SOIL'] = hru6.loc[index,'soil_ID_1']\n",
    "\n",
    "\n",
    "hru7 = hru6.drop(['index_left','LU_ID_1','LU_ID_2','soil_ID_1','soil_ID_2','soil_ID','LU_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086cea3e",
   "metadata": {},
   "source": [
    "### Section 5: Identifying major land use and soil classes in each subbasin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc45032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subbasin = gpd.read_file(subwshd_pth)\n",
    "# land use\n",
    "subbasin = subbasin.join(\n",
    "    pd.DataFrame(\n",
    "        zonal_stats(\n",
    "            vectors=subbasin['geometry'], \n",
    "            raster= lu_raster, \n",
    "            stats=['majority']\n",
    "        )\n",
    "    ),\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "subbasin['LU_major'] = subbasin['majority'].astype(int)\n",
    "subbasin = subbasin.drop(['majority'], axis=1)\n",
    "\n",
    "#soil\n",
    "subbasin = subbasin.join(\n",
    "    pd.DataFrame(\n",
    "        zonal_stats(\n",
    "            vectors=subbasin['geometry'], \n",
    "            raster= soil_raster, \n",
    "            stats=['majority']\n",
    "        )\n",
    "    ),\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "subbasin['soil_major'] = subbasin['majority'].astype(int)\n",
    "subbasin = subbasin.drop(['majority'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2e6f5",
   "metadata": {},
   "source": [
    "### Section 6: Identity: intersecct the hru7 with subbasin to cut the HRU's on subbasin limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2076d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hru8 = gpd.overlay(hru7, subbasin, how='intersection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8628a90",
   "metadata": {},
   "source": [
    "### Section 7: # calculate area of each land use class within each subbasin: This will be needed to dissolve small (based on a threshold given by user) land use classes by the major one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332166c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subbasin ['LUID_1'] = 0.  # No data\n",
    "subbasin ['LUID_2'] = 0.  # Water\n",
    "subbasin ['LUID_3'] = 0.  # Bare soil\n",
    "subbasin ['LUID_4'] = 0.  # deciduous forest\n",
    "subbasin ['LUID_5'] = 0.  # agricultur\n",
    "subbasin ['LUID_6'] = 0.  # coniferous forest\n",
    "subbasin ['LUID_7'] = 0.  # impermeable surface\n",
    "subbasin ['LUID_8'] = 0.  # peatland\n",
    "subbasin ['LUID_9'] = 0.  # wetland\n",
    "\n",
    "for index, row in subbasin.iterrows():\n",
    "    sub = subbasin.loc[subbasin['SubId'] == subbasin['SubId'][index]] # selects the subbasin a in the subbasin map\n",
    "    intersection = gpd.overlay(sub, lu_poly, how='intersection') # intersection operation\n",
    "    intersection['area'] = intersection.area  # the area of each row in the intersection   \n",
    "    subbasin.loc[index,'LUID_2'] = intersection.loc[intersection['LU_ID'] == 2,'area'].sum()\n",
    "    subbasin.loc[index,'LUID_3'] = intersection.loc[intersection['LU_ID'] == 3,'area'].sum()\n",
    "    subbasin.loc[index,'LUID_4'] = intersection.loc[intersection['LU_ID'] == 4,'area'].sum()\n",
    "    subbasin.loc[index,'LUID_5'] = intersection.loc[intersection['LU_ID'] == 5,'area'].sum()\n",
    "    subbasin.loc[index,'LUID_6'] = intersection.loc[intersection['LU_ID'] == 6,'area'].sum()\n",
    "    subbasin.loc[index,'LUID_7'] = intersection.loc[intersection['LU_ID'] == 7,'area'].sum()\n",
    "    subbasin.loc[index,'LUID_8'] = intersection.loc[intersection['LU_ID'] == 8,'area'].sum()\n",
    "    subbasin.loc[index,'LUID_9'] = intersection.loc[intersection['LU_ID'] == 9,'area'].sum()\n",
    "        \n",
    "os.chdir(workspace)\n",
    "subbasin.to_file('subbasin2.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b7b649",
   "metadata": {},
   "source": [
    "### Section 8: Defining the threshold and creating the aggregated HRU map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa216b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = hru8.columns\n",
    "merge = gpd.GeoDataFrame(columns = c,crs = hru8.crs)\n",
    "hru8['LU_agg'] = hru8['LU']\n",
    "Threshold = 5 # This is the threshold (%) based on which the land use classes covering smaller than that will be aggreagted to the major land use class\n",
    "for i in range(subbasin.shape[0]):\n",
    "    subwsh_number = i + 1\n",
    "    sub = subbasin.loc[subbasin['SubId'] == subwsh_number] # selects the subbasin a in the subbasin map\n",
    "    lu_major = sub['LU_major'][i]\n",
    "    area_total = sub['BasArea'][i]\n",
    "    perc_lu2 = (sub['LUID_2'][i]/area_total)*100.\n",
    "    perc_lu3 = (sub['LUID_3'][i]/area_total)*100.\n",
    "    perc_lu4 = (sub['LUID_4'][i]/area_total)*100.\n",
    "    perc_lu5 = (sub['LUID_5'][i]/area_total)*100.\n",
    "    perc_lu6 = (sub['LUID_6'][i]/area_total)*100.\n",
    "    perc_lu7 = (sub['LUID_7'][i]/area_total)*100.\n",
    "    perc_lu8 = (sub['LUID_8'][i]/area_total)*100.\n",
    "    perc_lu9 = (sub['LUID_9'][i]/area_total)*100.\n",
    "    # hru check and modifications\n",
    "    hru_temp = hru8.loc[hru8['SubId'] == subwsh_number] # selects the subbasin a in the subbasin map\n",
    "    for index, row in hru_temp.iterrows():\n",
    "        #check the percentage with threshold\n",
    "        # if (row.LU==2):\n",
    "        #     if (perc_lu2<=Threshold and perc_lu2>0 and row.Lake_Cat==0):\n",
    "        #         hru_temp.loc[index,'LU_agg'] = lu_major\n",
    "        if (row.LU==3):\n",
    "            if (perc_lu3<=Threshold and perc_lu3>0 and lu_major!=2):\n",
    "                hru_temp.loc[index,'LU_agg'] = lu_major        \n",
    "        if (row.LU==4):\n",
    "            if (perc_lu4<=Threshold and perc_lu4>0 and lu_major!=2):\n",
    "                hru_temp.loc[index,'LU_agg'] = lu_major  \n",
    "        if (row.LU==5):\n",
    "            if (perc_lu5<=Threshold and perc_lu5>0 and lu_major!=2):\n",
    "                hru_temp.loc[index,'LU_agg'] = lu_major  \n",
    "        if (row.LU==6):\n",
    "            if (perc_lu6<=Threshold and perc_lu6>0 and lu_major!=2):\n",
    "                hru_temp.loc[index,'LU_agg'] = lu_major  \n",
    "        if (row.LU==7):\n",
    "            if (perc_lu7<=Threshold and perc_lu7>0 and lu_major!=2):\n",
    "                hru_temp.loc[index,'LU_agg'] = lu_major  \n",
    "        if (row.LU==8):\n",
    "            if (perc_lu8<=Threshold and perc_lu8>0 and lu_major!=2):\n",
    "                hru_temp.loc[index,'LU_agg'] = lu_major  \n",
    "        if (row.LU==9):\n",
    "            if (perc_lu9<=Threshold and perc_lu9>0 and lu_major!=2):\n",
    "                hru_temp.loc[index,'LU_agg'] = lu_major\n",
    "    # import pdb; pdb.set_trace()\n",
    "    temp = hru_temp.dissolve(by = [\"LU_agg\",\"SOIL\"], as_index = False)\n",
    "    temp2 = merge.append(temp)\n",
    "    merge = temp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd351a3",
   "metadata": {},
   "source": [
    "### Section 9: Adding SOIL_PROF and LAND_USE_CODE fields (string) to the hru map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = merge.reset_index()\n",
    "merge['SOIL'] = merge['SOIL'].astype(int)\n",
    "merge['LU'] = merge['LU'].astype(int)\n",
    "merge['Soil_ID'] = merge['SOIL']\n",
    "merge['Landuse_ID'] = merge['LU_agg']\n",
    "\n",
    "st = {1:'sand', 2:'loamy_sand', 3:'sandy_loam', 4:'loam', 5:'silt_loam', 6:'silt', 7:'sandy_clay_loam', 8:'clay_loam', 9:'silty_clay_loam',\n",
    "      10:'sandy_clay', 11:'silty_clay', 12:'clay'}  # to be confirned with DEH\n",
    "\n",
    "merge['SOIL_PROF'] = merge['Soil_ID'].map(st)\n",
    "\n",
    "\n",
    "lu_codes = st = {1:'No_data', 2:'Water', 3:'bare_soil', 4:'deciduous_forest', 5:'agriculture', 6:'coniferous_forest', 7:'impermeable_surface', 8:'peatland', 9:'wetland'}  # to be confirned with DEH\n",
    "\n",
    "merge['LAND_USE_CODE'] = merge['LU_agg'].map(lu_codes)\n",
    "\n",
    "\n",
    "os.chdir(workspace)\n",
    "merge.to_file('hru10.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba380d81",
   "metadata": {},
   "source": [
    "### Section10: Add latitude,longitude, HRU ID, Slope, aspect, and Elevation to the HRU feature class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ead7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# adding HRU_ID\n",
    "merge['HRU_ID'] = 0\n",
    "j=1\n",
    "for index, row in merge.iterrows():\n",
    "    merge.loc[index,'HRU_ID'] = j\n",
    "    j = j+1\n",
    "\n",
    "\n",
    "# calculating the ara of each HRU polygon in m2\n",
    "merge['HRU_Area'] = merge.area  \n",
    "\n",
    "# adding mean elevation of each HRU \n",
    "\n",
    "#elevation\n",
    "\n",
    "merge = merge.join(\n",
    "    pd.DataFrame(\n",
    "        zonal_stats(\n",
    "            vectors=merge['geometry'], \n",
    "            raster= altitude, \n",
    "            stats=['mean']\n",
    "        )\n",
    "    ),\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "merge['HRU_E_mean'] = merge['mean']\n",
    "merge = merge.drop(['mean'], axis=1)\n",
    "\n",
    "\n",
    "#aspect\n",
    "\n",
    "merge = merge.join(\n",
    "    pd.DataFrame(\n",
    "        zonal_stats(\n",
    "            vectors=merge['geometry'], \n",
    "            raster= aspect, \n",
    "            stats=['mean']\n",
    "        )\n",
    "    ),\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "merge['HRU_A_mean'] = merge['mean']\n",
    "merge = merge.drop(['mean'], axis=1)\n",
    "\n",
    "\n",
    "# adding mean slope\n",
    "\n",
    "\n",
    "# pth5 = os.path.join(workspace,\"subbasin\"+ \".\" + \"shp\") # The lake shape file created by Physitel\n",
    "# subbasin = gpd.read_file(pth5)\n",
    "\n",
    "merge = merge.join(\n",
    "    pd.DataFrame(\n",
    "        zonal_stats(\n",
    "            vectors=merge['geometry'], \n",
    "            raster= slope, \n",
    "            stats=['mean']\n",
    "        )\n",
    "    ),\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "merge.loc[merge['mean'] < 0 , \"mean\"] = 0 \n",
    "\n",
    "merge['HRU_S_mean'] = merge['mean']\n",
    "merge = merge.drop(['mean'], axis=1)\n",
    "\n",
    "# adding latitude, longitude\n",
    "\n",
    "merge['HRU_CenX'] = merge.centroid.x\n",
    "merge['HRU_CenY'] = merge.centroid.y\n",
    "\n",
    "\n",
    "\n",
    "merge = merge.drop(['index_left','ident','index','OBJECTID','LU_major','soil_major','LU_agg','LU','SOIL'], axis=1)\n",
    "\n",
    "\n",
    "os.chdir(workspace)\n",
    "merge.to_file('hru_final.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

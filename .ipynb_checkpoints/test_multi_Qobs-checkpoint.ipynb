{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import re,os\n",
    "import xarray as xr\n",
    "from typing import Optional, Tuple, Union\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56998b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mohammad/Dossier_travail/Raven/test_Q_deh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc42e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta_patterns = {\n",
    "    \"Station: \": \"name\",\n",
    "    \"Bassin versant: \": \"bv\",\n",
    "    \"Coordonnées: (NAD83) \": \"coords\",\n",
    "}\n",
    "\n",
    "\n",
    "data_header_pattern = \"Station Date Débit (m³/s) Remarque\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)\n",
    "files = glob (\"*.txt\")\n",
    "dataset = pd.DataFrame(columns = [\"station_id\"])\n",
    "latitude = pd.DataFrame(columns={'station_id','lat'},index = None)\n",
    "longitude = pd.DataFrame(columns={'station_id','lon'},index = None)\n",
    "\n",
    "for i in range(len(files)): \n",
    "    fname = os.path.join(path,files[i])\n",
    "    print(\"writing station:\",files[i])\n",
    "    with open(fname, encoding=\"latin1\") as fh:\n",
    "        txt = fh.read()\n",
    "        txt = re.sub(\" +\", \" \", txt)\n",
    "        meta, data = txt.split(data_header_pattern)\n",
    "\n",
    "    m = dict()\n",
    "    for key in meta_patterns:\n",
    "    # Various possible separators to take into account\n",
    "        m[meta_patterns[key]] = (\n",
    "            meta.split(key)[1].split(\" \\n\")[0].split(\"\\n\")[0].split(\" Régime\")[0]\n",
    "            )\n",
    "    d = pd.read_csv(\n",
    "    fname,\n",
    "    delimiter=r\"\\s+\",\n",
    "    skiprows=len(meta.splitlines()),\n",
    "    encoding=\"latin1\",\n",
    "    converters={0: lambda x: str(x)},  # noqa\n",
    "    index_col=1,\n",
    "    parse_dates=True,\n",
    "    infer_datetime_format=True,\n",
    ")\n",
    "    d = d.drop(['Remarque','(m³/s)'], axis=1)\n",
    "    #d=d.dropna()\n",
    "    d = d.fillna(-1.2345)  # fill NaNs with -1.2345\n",
    "    if len(d[\"Station\"].unique()) == 1:\n",
    "        m[\"station\"] = d[\"Station\"].unique()[0]\n",
    "        d = d.drop(\"Station\", axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"Multiple stations detected in the same file.\")\n",
    "    d = d.rename(columns={\"Débit\":'qobs'})\n",
    "    d.index.names = [\"time\"]\n",
    "#    d = d.drop(\"Nan\", axis=1)\n",
    "    \n",
    "    # finding latitude (in decimal degree)\n",
    "    coords = m[\"coords\"].split(\" // \")  \n",
    "    deg, minutes, seconds, _ = re.split(\"[°'\\\"]\", coords[0])\n",
    "\n",
    "    if float(deg) > 0:\n",
    "        lat =  round(\n",
    "            float(deg) + float(minutes) / 60 + float(seconds) / (60 * 60), 6\n",
    "        )\n",
    "    else:\n",
    "        lat =  round(float(deg) - (float(minutes) / 60 + float(seconds) / (60 * 60)), 6)\n",
    "\n",
    "    # finding longitude (in decimal degree)\n",
    "    coords = m[\"coords\"].split(\" // \")  \n",
    "    deg, minutes, seconds, _ = re.split(\"[°'\\\"]\", coords[1])\n",
    "\n",
    "    if float(deg) > 0:\n",
    "        lon =  round(\n",
    "            float(deg) + float(minutes) / 60 + float(seconds) / (60 * 60), 6\n",
    "        )\n",
    "    else:\n",
    "        lon =  round(float(deg) - (float(minutes) / 60 + float(seconds) / (60 * 60)), 6)\n",
    "    \n",
    "    d['lon'] = lon\n",
    "    d['lat'] = lat\n",
    "    d['station_id'] = m['station']\n",
    "    \n",
    "    lt = pd.DataFrame(d,columns={'station_id','lat'},index = None)\n",
    "    lo = pd.DataFrame(d,columns={'station_id','lon'},index = None)\n",
    "    d = d.drop(\"lat\", axis=1)\n",
    "    d = d.drop(\"lon\", axis=1)\n",
    "\n",
    "    \n",
    "    dataset = pd.concat([dataset,d],join = 'outer')\n",
    "    latitude = pd.concat([latitude,lt],join = 'outer')\n",
    "    longitude = pd.concat([longitude,lo],join = 'outer')\n",
    "    \n",
    "    latitude = latitude.drop_duplicates(subset = [\"station_id\"])\n",
    "    longitude = longitude.drop_duplicates(subset = [\"station_id\"])\n",
    "    \n",
    "    \n",
    "    del d,m,coords,lat,lon,deg,minutes,seconds,fname,meta,data,lt,lo\n",
    "\n",
    "dataset = dataset.rename_axis('time').reset_index()\n",
    "\n",
    "dataset = dataset.set_index(['station_id', 'time'])\n",
    "dataset = dataset[~dataset.index.duplicated(keep='first')]\n",
    "\n",
    "ds = dataset.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8027051",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = latitude.set_index(['station_id','lat']).to_xarray()\n",
    "ds3 = longitude.set_index(['station_id','lon']).to_xarray()\n",
    "\n",
    "ds_merged = xr.merge([ds, ds2,ds3])\n",
    "\n",
    "ds.to_netcdf(\"SLSO_qobs.nc\",'w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
